{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0317331c",
   "metadata": {},
   "source": [
    "### Consumer Prices Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934493fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a3fd5f",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_prices_indicators = pd.read_csv(\"../Consumer prices indicators - FAOSTAT_data_en_2-22-2024.csv\")\n",
    "consumer_prices_indicators.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8952d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = consumer_prices_indicators.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b81faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "consumer_prices_cleaned = consumer_prices_indicators.dropna(axis=0).reset_index(drop=True)\n",
    "consumer_prices_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "consumer_prices_cleaned = consumer_prices_indicators.dropna(axis=1).reset_index(drop=True)\n",
    "consumer_prices_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fbb54f",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e57ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in consumer_prices_cleaned.columns:\n",
    "    if consumer_prices_cleaned[col].dtype == 'object':\n",
    "        consumer_prices_cleaned[col] = label_encoder.fit_transform(consumer_prices_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(consumer_prices_cleaned), columns=consumer_prices_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e958628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in consumer_prices_cleaned.columns:\n",
    "    if consumer_prices_cleaned[col].dtype == 'object':\n",
    "        consumer_prices_cleaned[col] = label_encoder.fit_transform(consumer_prices_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(consumer_prices_cleaned), columns=consumer_prices_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d08fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a53b117",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e5c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Area Code (M49)', 'Value', 'Domain Code',\t'Domain', 'Area', 'Year Code', 'Year', 'Item Code', 'Item',\t'Months Code', 'Months', 'Element Code', 'Element', 'Flag', 'Flag Description']\n",
    "consumer_prices_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142fbf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "# X = consumer_prices_selected[['Area Code (M49)', 'Year', 'Item Code', 'Months Code']]\n",
    "X = consumer_prices_selected[['Area Code (M49)', 'Domain Code', 'Domain', 'Area', 'Year Code', 'Year', 'Item Code', 'Item',\t'Months Code', 'Months', 'Element Code', 'Element', 'Flag', 'Flag Description']]\n",
    "y = consumer_prices_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd46cfe",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a92716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40849e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d9a934",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81264fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f31d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2cf68a",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739de942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c29e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118aed5",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930eebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = consumer_prices_indicators[['Area', 'Year Code']]\n",
    "\n",
    "consumer_prices_indicators_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "consumer_prices_indicators_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3bb4a",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd79c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = consumer_prices_indicators_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = consumer_prices_indicators_area_concat[consumer_prices_indicators_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_consumer_prices_indicators/model_consumer_prices_indicators_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20843147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_consumer_prices_indicators/model_consumer_prices_indicators_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = consumer_prices_indicators_area_concat['Area'].unique()\n",
    "forecast_results = {}   \n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Bahamas', 'Bangladesh', 'India']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598fa900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54a10492",
   "metadata": {},
   "source": [
    "### Crops Production Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f77e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe8668d",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1873220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_production_indicators = pd.read_csv(\"../Crops production indicators - FAOSTAT_data_en_2-22-2024.csv\")\n",
    "crops_production_indicators.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bed68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = crops_production_indicators.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a912342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "crops_production_indicators_cleaned = crops_production_indicators.dropna(axis=0).reset_index(drop=True)\n",
    "crops_production_indicators_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed843c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "crops_production_indicators_cleaned = crops_production_indicators.dropna(axis=1).reset_index(drop=True)\n",
    "crops_production_indicators_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d776ec79",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4795a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in crops_production_indicators_cleaned.columns:\n",
    "    if crops_production_indicators_cleaned[col].dtype == 'object':\n",
    "        crops_production_indicators_cleaned[col] = label_encoder.fit_transform(crops_production_indicators_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(crops_production_indicators_cleaned), columns=crops_production_indicators_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in crops_production_indicators_cleaned.columns:\n",
    "    if crops_production_indicators_cleaned[col].dtype == 'object':\n",
    "        crops_production_indicators_cleaned[col] = label_encoder.fit_transform(crops_production_indicators_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(crops_production_indicators_cleaned), columns=crops_production_indicators_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab1ae2d",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b257d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code (CPC)', 'Item', 'Year Code',\t'Year',\t'Unit',\t'Value', 'Flag', 'Flag Description']\n",
    "crops_production_indicators_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352550fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = crops_production_indicators_selected[['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code (CPC)', 'Item', 'Year Code', 'Year', 'Unit', 'Flag', 'Flag Description']]\n",
    "y = crops_production_indicators_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ceacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7360367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2581d0a8",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f556c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9766e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c906ca",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e52a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664de83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e87e7a",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f03f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9eea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e986a74d",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b41adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = crops_production_indicators[['Area', 'Year Code']]\n",
    "\n",
    "crops_production_indicators_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "crops_production_indicators_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0acf60a",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18efb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = crops_production_indicators_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = crops_production_indicators_area_concat[crops_production_indicators_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_crops_production_indicators/model_crops_production_indicators_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2124a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_crops_production_indicators/model_crops_production_indicators_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = crops_production_indicators_area_concat['Area'].unique()\n",
    "forecast_results = {}   \n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Austria', 'Zambia', 'Viet Nam']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5960f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "806a0ce5",
   "metadata": {},
   "source": [
    "### Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b745f3",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d70a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "employment = pd.read_csv(\"../Employment - FAOSTAT_data_en_2-27-2024.csv\")\n",
    "employment.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = employment.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb3c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "employment_cleaned = employment.dropna(axis=0).reset_index(drop=True)\n",
    "employment_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "employment_cleaned = employment.dropna(axis=1).reset_index(drop=True)\n",
    "employment_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b068dee1",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50657e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in employment_cleaned.columns:\n",
    "    if employment_cleaned[col].dtype == 'object':\n",
    "        employment_cleaned[col] = label_encoder.fit_transform(employment_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(employment_cleaned), columns=employment_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366f1aa",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Indicator Code', 'Indicator', 'Sex Code', 'Sex', 'Year Code', 'Year', 'Element Code', 'Element', 'Source Code', 'Source', 'Unit', 'Value', 'Flag', 'Flag Description']\n",
    "employment_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = employment_selected[['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Indicator Code', 'Indicator', 'Sex Code', 'Sex', 'Year Code', 'Year', 'Element Code', 'Element', 'Source Code', 'Source', 'Unit', 'Flag', 'Flag Description']]\n",
    "y = employment_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64fad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ff1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5369b",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59be55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d04180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9614ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e23a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd8df9b",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c14ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9002077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde2328e",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26edf456",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648925c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5356958",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = employment[['Area', 'Year Code']]\n",
    "\n",
    "employment_cleaned_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "employment_cleaned_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae4b17",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dec972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = employment_cleaned_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = employment_cleaned_area_concat[employment_cleaned_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_employment/model_employment_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f87af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_employment/model_employment_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = employment_cleaned_area_concat['Area'].unique()\n",
    "forecast_results = {}   \n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Bahamas', 'Bangladesh', 'India']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d599d9",
   "metadata": {},
   "source": [
    "### Exchange Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae5d95",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47144f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rate = pd.read_csv(\"../Exchange rate - FAOSTAT_data_en_2-22-2024.csv\")\n",
    "exchange_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcb84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = exchange_rate.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "exchange_rate_cleaned = exchange_rate.dropna(axis=0).reset_index(drop=True)\n",
    "exchange_rate_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac9ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "exchange_rate_cleaned = exchange_rate.dropna(axis=1).reset_index(drop=True)\n",
    "exchange_rate_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8c5ea9",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92802d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in exchange_rate_cleaned.columns:\n",
    "    if exchange_rate_cleaned[col].dtype == 'object':\n",
    "        exchange_rate_cleaned[col] = label_encoder.fit_transform(exchange_rate_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(exchange_rate_cleaned), columns=exchange_rate_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd8a31",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2547c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'ISO Currency Code (FAO)', 'Currency', 'Element Code', 'Element', 'Year Code', 'Year', 'Months Code', 'Months', 'Value', 'Flag', 'Flag Description']\n",
    "exchange_rate_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c3c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = exchange_rate_selected[['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'ISO Currency Code (FAO)', 'Currency', 'Element Code', 'Element', 'Year Code', 'Year', 'Months Code', 'Months', 'Flag', 'Flag Description']]\n",
    "y = exchange_rate_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff111e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca845c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ad2f9",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbcda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbf70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5fec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe671999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35db6d1a",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ba2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e609f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a694327",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ea144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231f7505",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f4cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = exchange_rate[['Area', 'Year Code']]\n",
    "\n",
    "exchange_rate_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "exchange_rate_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd794664",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1dba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = exchange_rate_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = exchange_rate_area_concat[exchange_rate_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_exchange_rate/model_exchange_rate_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_exchange_rate/model_exchange_rate_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = exchange_rate_area_concat['Area'].unique()\n",
    "forecast_results = {}   \n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Bahamas', 'Bangladesh', 'India']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0714bd",
   "metadata": {},
   "source": [
    "### Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286db85",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b44327",
   "metadata": {},
   "outputs": [],
   "source": [
    "emmissions = pd.read_csv(\"../Emissions - FAOSTAT_data_en_2-27-2024.csv\")\n",
    "emmissions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72db0ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = emmissions.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "emmissions_cleaned = emmissions.dropna(axis=0).reset_index(drop=True)\n",
    "emmissions_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "emmissions_cleaned = emmissions.dropna(axis=1).reset_index(drop=True)\n",
    "emmissions_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cea0b0",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in emmissions_cleaned.columns:\n",
    "    if emmissions_cleaned[col].dtype == 'object':\n",
    "        emmissions_cleaned[col] = label_encoder.fit_transform(emmissions_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(emmissions_cleaned), columns=emmissions_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b353f443",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4632d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code (CPC)', 'Item', 'Year Code', 'Year', 'Source Code', 'Source', 'Unit', 'Value', 'Flag', 'Flag Description']\n",
    "emmissions_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6099ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = emmissions_selected[['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code (CPC)', 'Item', 'Year Code', 'Year', 'Source Code', 'Source', 'Unit', 'Flag', 'Flag Description']]\n",
    "y = emmissions_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9fcadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba9b70",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0764ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2489ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3719785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a57cc4",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d0037",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdacefc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b68af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a67f22",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a6f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = emmissions[['Area', 'Year Code']]\n",
    "\n",
    "emissions_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "emissions_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0b141",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = emissions_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = emissions_area_concat[emissions_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_emissions/model_emissions_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8432917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_emissions/model_emissions_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = emissions_area_concat['Area'].unique()\n",
    "forecast_results = {}\n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Angola', 'Bangladesh', 'Yemen']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e840c0",
   "metadata": {},
   "source": [
    "### Fertilizers Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd660a6",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887469cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fertilizers_use = pd.read_csv(\"../Fertilizers use - FAOSTAT_data_en_2-27-2024.csv\")\n",
    "fertilizers_use.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c083bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = fertilizers_use.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c508ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "fertilizers_use_cleaned = fertilizers_use.dropna(axis=0).reset_index(drop=True)\n",
    "fertilizers_use_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946fcf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "fertilizers_use_cleaned = fertilizers_use.dropna(axis=1).reset_index(drop=True)\n",
    "fertilizers_use_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3053d725",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975708cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in fertilizers_use_cleaned.columns:\n",
    "    if fertilizers_use_cleaned[col].dtype == 'object':\n",
    "        fertilizers_use_cleaned[col] = label_encoder.fit_transform(fertilizers_use_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(fertilizers_use_cleaned), columns=fertilizers_use_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25537be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e493d37",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d778ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code', 'Item', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Flag Description']\n",
    "fertilizers_use_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be175de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = fertilizers_use_selected[['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code', 'Item', 'Year Code', 'Year', 'Unit', 'Flag', 'Flag Description']]\n",
    "y = fertilizers_use_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c2242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890324c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc8568",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4512e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ba281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc07aab7",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe15cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d200f77",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b844eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1564bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901db826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e0601",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab2477",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = fertilizers_use[['Area', 'Year Code']]\n",
    "\n",
    "fertilizers_use_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "fertilizers_use_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca86ce7",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069da029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = fertilizers_use_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = fertilizers_use_area_concat[fertilizers_use_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_fertilizers_use/model_fertilizers_use_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a44f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_fertilizers_use/model_fertilizers_use_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = fertilizers_use_area_concat['Area'].unique()\n",
    "forecast_results = {}   \n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Barbados', 'Bangladesh', 'Ukraine']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77732f6e",
   "metadata": {},
   "source": [
    "### Food Balances Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5e0601",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_balances_indicators = pd.read_csv(\"../Food balances indicators - FAOSTAT_data_en_2-22-2024.csv\")\n",
    "food_balances_indicators.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbdf0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = food_balances_indicators.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d2546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "food_balances_indicators_cleaned = food_balances_indicators.dropna(axis=0).reset_index(drop=True)\n",
    "food_balances_indicators_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "food_balances_indicators_cleaned = food_balances_indicators.dropna(axis=1).reset_index(drop=True)\n",
    "food_balances_indicators_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe5e8e7",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in food_balances_indicators_cleaned.columns:\n",
    "    if food_balances_indicators_cleaned[col].dtype == 'object':\n",
    "        food_balances_indicators_cleaned[col] = label_encoder.fit_transform(food_balances_indicators_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(food_balances_indicators_cleaned), columns=food_balances_indicators_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbf8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83959b",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b584e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code (FBS)', 'Item', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Flag Description']\n",
    "food_balances_indicators_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aeedef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = food_balances_indicators_selected[['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code (FBS)', 'Item', 'Year Code', 'Year', 'Unit', 'Flag', 'Flag Description']]\n",
    "y = food_balances_indicators_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85afbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93543170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73672e0",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba19026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa23102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043640c",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00707ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259575e",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac56f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d5de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca98a52",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e539cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = food_balances_indicators[['Area', 'Year Code']]\n",
    "\n",
    "food_balances_indicators_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "food_balances_indicators_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf52aec",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d75e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = food_balances_indicators_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = food_balances_indicators_area_concat[food_balances_indicators_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_food_balances_indicators/model_food_balances_indicators_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ff4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_food_balances_indicators/model_food_balances_indicators_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = food_balances_indicators_area_concat['Area'].unique()\n",
    "forecast_results = {}   \n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Bahamas', 'Bangladesh', 'India']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf45ebff",
   "metadata": {},
   "source": [
    "### Food Security Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be50f496",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed24da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_security_indicators = pd.read_csv(\"../Food security indicators  - FAOSTAT_data_en_2-22-2024.csv\")\n",
    "food_security_indicators.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28653050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = food_security_indicators.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e140c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "food_security_indicators_cleaned = food_security_indicators.dropna(axis=0).reset_index(drop=True)\n",
    "food_security_indicators_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5789fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "food_security_indicators_cleaned = food_security_indicators.dropna(axis=1).reset_index(drop=True)\n",
    "food_security_indicators_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8306e19f",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1eeea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in food_security_indicators_cleaned.columns:\n",
    "    if food_security_indicators_cleaned[col].dtype == 'object':\n",
    "        food_security_indicators_cleaned[col] = label_encoder.fit_transform(food_security_indicators_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(food_security_indicators_cleaned), columns=food_security_indicators_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d0442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a3f75",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code', 'Item', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Flag Description']\n",
    "food_security_indicators_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = food_security_indicators_selected[['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code', 'Item', 'Year Code', 'Year', 'Unit', 'Flag', 'Flag Description']]\n",
    "y = food_security_indicators_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306af353",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ba3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600e75e",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87dee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2beec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75c3b0",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95fa8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d241d",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e96eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f613e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960bb9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f8f81",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = food_security_indicators[['Area', 'Year Code']]\n",
    "\n",
    "food_security_indicators_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "food_security_indicators_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f560f8",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2274d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = food_security_indicators_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = food_security_indicators_area_concat[food_security_indicators_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_food_security_indicators/model_food_security_indicators_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_food_security_indicators/model_food_security_indicators_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = food_security_indicators_area_concat['Area'].unique()\n",
    "forecast_results = {}   \n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Bahamas', 'Bangladesh', 'India']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293a702",
   "metadata": {},
   "source": [
    "### Food Trade Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaafa0af",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_trade_indicators = pd.read_csv(\"../Food trade indicators - FAOSTAT_data_en_2-22-2024.csv\")\n",
    "food_trade_indicators.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca62c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = food_trade_indicators.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a2215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "food_trade_indicators_cleaned = food_trade_indicators.dropna(axis=0).reset_index(drop=True)\n",
    "food_trade_indicators_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d24800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "food_trade_indicators_cleaned = food_trade_indicators.dropna(axis=1).reset_index(drop=True)\n",
    "food_trade_indicators_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3823bd6",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31477007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in food_trade_indicators_cleaned.columns:\n",
    "    if food_trade_indicators_cleaned[col].dtype == 'object':\n",
    "        food_trade_indicators_cleaned[col] = label_encoder.fit_transform(food_trade_indicators_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(food_trade_indicators_cleaned), columns=food_trade_indicators_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07173ca",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26543c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code (CPC)', 'Item', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Flag Description']\n",
    "food_trade_indicators_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = food_trade_indicators_selected[['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code (CPC)', 'Item', 'Year Code', 'Year', 'Unit', 'Flag', 'Flag Description']]\n",
    "y = food_trade_indicators_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be462a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6587c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df9222e",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f78af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcc3df2",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42ef8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36453a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacb1441",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520be5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d32064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9eb994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a184bde",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = food_trade_indicators[['Area', 'Year Code']]\n",
    "\n",
    "food_trade_indicators_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "food_trade_indicators_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bea9a",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a317036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = food_trade_indicators_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = food_trade_indicators_area_concat[food_trade_indicators_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_food_trade_indicators/model_food_trade_indicators_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_food_trade_indicators/model_food_trade_indicators_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = food_trade_indicators_area_concat['Area'].unique()\n",
    "forecast_results = {}   \n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Bahamas', 'Bangladesh', 'India']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c583b966",
   "metadata": {},
   "source": [
    "### Foriegn Direct Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d889f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ed3f5b",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "foriegn_direct_investment = pd.read_csv(\"../Foreign direct investment - FAOSTAT_data_en_2-27-2024.csv\")\n",
    "foriegn_direct_investment.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1617999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = foriegn_direct_investment.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5319dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "foriegn_direct_investment_cleaned = foriegn_direct_investment.dropna(axis=0).reset_index(drop=True)\n",
    "foriegn_direct_investment_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "foriegn_direct_investment_cleaned = foriegn_direct_investment.dropna(axis=1).reset_index(drop=True)\n",
    "foriegn_direct_investment_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dfb2d9",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab16bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in foriegn_direct_investment_cleaned.columns:\n",
    "    if foriegn_direct_investment_cleaned[col].dtype == 'object':\n",
    "        foriegn_direct_investment_cleaned[col] = label_encoder.fit_transform(foriegn_direct_investment_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(foriegn_direct_investment_cleaned), columns=foriegn_direct_investment_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8048972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37fc01f",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code', 'Item', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Flag Description', 'Note']\n",
    "foriegn_direct_investment_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "# X = consumer_prices_selected[['Area Code (M49)', 'Year', 'Item Code', 'Months Code']]\n",
    "X = foriegn_direct_investment_selected[['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code', 'Item', 'Year Code', 'Year', 'Unit','Flag', 'Flag Description', 'Note']]\n",
    "y = foriegn_direct_investment_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b94ac",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b29c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d474f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc1833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981d61a",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63ab95",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0584ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae153d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2696b",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8248e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = foriegn_direct_investment[['Area', 'Year Code']]\n",
    "\n",
    "foriegn_direct_investment_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "foriegn_direct_investment_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421459c",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = foriegn_direct_investment_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = foriegn_direct_investment_area_concat[foriegn_direct_investment_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_foriegn_direct_investment/model_foriegn_direct_investment_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9fdac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_foriegn_direct_investment/model_foriegn_direct_investment_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = foriegn_direct_investment_area_concat['Area'].unique()\n",
    "forecast_results = {}   \n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Bahamas', 'Bangladesh', 'India']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a4ef5c",
   "metadata": {},
   "source": [
    "### Land Temperature Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c33d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff434e70",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88b94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_temperature_change = pd.read_csv(\"../Land temperature change - FAOSTAT_data_en_2-27-2024.csv\")\n",
    "land_temperature_change.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3e1d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = land_temperature_change.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8780a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "land_temperature_change_cleaned = land_temperature_change.dropna(axis=0).reset_index(drop=True)\n",
    "land_temperature_change_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8067ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "# land_temperature_change_cleaned = land_temperature_change.dropna(axis=1).reset_index(drop=True)\n",
    "# land_temperature_change_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32611f1c",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63bd0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in land_temperature_change_cleaned.columns:\n",
    "    if land_temperature_change_cleaned[col].dtype == 'object':\n",
    "        land_temperature_change_cleaned[col] = label_encoder.fit_transform(land_temperature_change_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(land_temperature_change_cleaned), columns=land_temperature_change_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a30debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41467ebd",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Months Code', 'Months', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Flag Description']\n",
    "land_temperature_change_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9402901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "# X = consumer_prices_selected[['Area Code (M49)', 'Year', 'Item Code', 'Months Code']]\n",
    "X = land_temperature_change_selected[['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Months Code', 'Months', 'Year Code', 'Year', 'Unit', 'Flag', 'Flag Description']]\n",
    "y = land_temperature_change_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48570d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf2fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d174a",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f695561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f996714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78166a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dbc9b0",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a090e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cddff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec08852e",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188fc369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ccd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4aa02",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = land_temperature_change[['Area', 'Year Code']]\n",
    "\n",
    "land_temperature_change_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "land_temperature_change_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a467b7",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f8a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = land_temperature_change_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = land_temperature_change_area_concat[land_temperature_change_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "\n",
    "    imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "    X_region = imputer.fit_transform(X_region)\n",
    "    y_region = imputer.fit_transform(y_region.values.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_land_temperature_change/model_land_temperature_change_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_land_temperature_change/model_land_temperature_change_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = land_temperature_change_area_concat['Area'].unique()\n",
    "forecast_results = {}   \n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Nigeria', 'Bangladesh', 'Belarus']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f149763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6648c82",
   "metadata": {},
   "source": [
    "### Land Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3999386",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a14c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use = pd.read_csv(\"../Land use - FAOSTAT_data_en_2-22-2024.csv\")\n",
    "land_use.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = land_use.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "land_use_cleaned = land_use.dropna(axis=0).reset_index(drop=True)\n",
    "land_use_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "land_use_cleaned = land_use.dropna(axis=1).reset_index(drop=True)\n",
    "land_use_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48310b6e",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in land_use_cleaned.columns:\n",
    "    if land_use_cleaned[col].dtype == 'object':\n",
    "        land_use_cleaned[col] = label_encoder.fit_transform(land_use_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(land_use_cleaned), columns=land_use_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65167ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e3d44",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c12592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code', 'Item', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Flag Description']\n",
    "land_use_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "# X = consumer_prices_selected[['Area Code (M49)', 'Year', 'Item Code', 'Months Code']]\n",
    "X = land_use_selected[['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code', 'Item', 'Year Code', 'Year', 'Unit', 'Flag', 'Flag Description']]\n",
    "y = land_use_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94477259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ab4274",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff97139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f30b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb83b953",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7da06fd",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671053dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f95571d",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = land_use[['Area', 'Year Code']]\n",
    "\n",
    "land_use_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "land_use_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f4819a",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e6c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = land_use_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = land_use_area_concat[land_use_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_land_use/model_land_use_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_land_use/model_land_use_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = land_use_area_concat['Area'].unique()\n",
    "forecast_results = {}   \n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Bahamas', 'Bangladesh', 'India']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefec334",
   "metadata": {},
   "source": [
    "### Pesticides Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd1440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4f50a",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesticides_use = pd.read_csv(\"../Pesticides use - FAOSTAT_data_en_2-27-2024.csv\")\n",
    "pesticides_use.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = pesticides_use.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb403eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "pesticides_use_cleaned = pesticides_use.dropna(axis=0).reset_index(drop=True)\n",
    "pesticides_use_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ed258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values if any\n",
    "pesticides_use_cleaned = pesticides_use.dropna(axis=1).reset_index(drop=True)\n",
    "pesticides_use_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c09a1a",
   "metadata": {},
   "source": [
    "### Converting Categorial colunm to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in pesticides_use_cleaned.columns:\n",
    "    if pesticides_use_cleaned[col].dtype == 'object':\n",
    "        pesticides_use_cleaned[col] = label_encoder.fit_transform(pesticides_use_cleaned[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialized MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing all columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(pesticides_use_cleaned), columns=pesticides_use_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39339e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b21d9",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b63c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code', 'Item', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Flag Description']\n",
    "pesticides_use_selected = df_normalized[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = pesticides_use_selected[['Domain Code', 'Domain', 'Area Code (M49)', 'Area', 'Element Code', 'Element', 'Item Code', 'Item', 'Year Code', 'Year', 'Unit', 'Flag', 'Flag Description']]\n",
    "y = pesticides_use_selected['Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7844569",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80%, 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c3bfd",
   "metadata": {},
   "source": [
    "### # Plot the relationship between each two variables to spot anything incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c021b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between each two variables to spot anything incorrect.\n",
    "train_stats = X_train.describe()\n",
    "sns.pairplot(train_stats[train_stats.columns], diag_kind=\"kde\") # or diag_kind='reg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ac5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ec08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(\"Linear Regression Mean Squared Error:\", lr_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d4dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_predictions)\n",
    "print(\"MLP Regression Mean Squared Error:\", mlp_mse)\n",
    "print(\"MLP Regression Mean Absolute Error:\", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e2c76",
   "metadata": {},
   "source": [
    "### Model Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_lr = pd.DataFrame({'Actual': y_test, 'Predicted_LR': lr_predictions})\n",
    "plot_data_mlp = pd.DataFrame({'Actual': y_test, 'Predicted_MLP': mlp_predictions})\n",
    "\n",
    "# Plot actual vs predicted values for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_lr, x='Actual', y='Predicted_LR', scatter_kws={'color': 'orange'}, line_kws={'color': 'green'})\n",
    "plt.title('Actual vs Predicted Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=plot_data_mlp, x='Actual', y='Predicted_MLP', scatter_kws={'color': 'green'}, line_kws={'color': 'orange'})\n",
    "plt.title('Actual vs Predicted Values (MLP Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression\n",
    "lr_residuals = y_test - lr_predictions\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot residuals for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(lr_residuals, color='blue', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (Linear Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals for MLP Regression\n",
    "mlp_residuals = y_test - mlp_predictions\n",
    "\n",
    "# Plot residuals for MLP Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(mlp_residuals, color='green', fill=True, alpha=0.5, linewidth=0)\n",
    "plt.title('Residuals Distribution (MLP Regression)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368c5ed",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eadd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# Validate the models using cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "lr_rmse_scores = np.sqrt(-lr_scores)\n",
    "print(\"Linear Regression Cross-Validation RMSE Scores:\", lr_rmse_scores)\n",
    "print(\"Linear Regression Mean RMSE:\", lr_rmse_scores.mean())\n",
    "\n",
    "mlp_scores = cross_val_score(mlp_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "mlp_rmse_scores = np.sqrt(-mlp_scores)\n",
    "print(\"MLP Cross-Validation RMSE Scores:\", mlp_rmse_scores)\n",
    "print(\"MLP Mean RMSE:\", mlp_rmse_scores.mean())\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Learning curve for Linear Regression\n",
    "train_sizes_lr, train_scores_lr, test_scores_lr = learning_curve(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_lr = np.sqrt(-train_scores_lr.mean(axis=1))\n",
    "test_rmse_lr = np.sqrt(-test_scores_lr.mean(axis=1))\n",
    "plt.plot(train_sizes_lr, train_rmse_lr, 'o-', color='blue', label='Train (Linear Regression)')\n",
    "plt.plot(train_sizes_lr, test_rmse_lr, 'o-', color='cyan', label='Test (Linear Regression)')\n",
    "\n",
    "# Learning curve for MLP Regression\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_rmse_mlp = np.sqrt(-train_scores_mlp.mean(axis=1))\n",
    "test_rmse_mlp = np.sqrt(-test_scores_mlp.mean(axis=1))\n",
    "plt.plot(train_sizes_mlp, train_rmse_mlp, 'o-', color='green', label='Train (MLP Regression)')\n",
    "plt.plot(train_sizes_mlp, test_rmse_mlp, 'o-', color='lightgreen', label='Test (MLP Regression)')\n",
    "\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c19b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Area'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Year Code'], inplace=True)\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a50cedc",
   "metadata": {},
   "source": [
    "### Concatenate `Area` , `Year Code` Categorical Variable into the normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c913d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_column = pesticides_use[['Area', 'Year Code']]\n",
    "\n",
    "pesticides_use_area_concat = pd.concat([df_normalized, area_column], axis=1)\n",
    "\n",
    "pesticides_use_area_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec1f652",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361bec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a separate model for each geographical region and save them\n",
    "regions = pesticides_use_area_concat['Area'].unique()\n",
    "for region in regions:\n",
    "    region_data = pesticides_use_area_concat[pesticides_use_area_concat['Area'] == region]\n",
    "    X_region = region_data[['Year']]\n",
    "    y_region = region_data['Value']\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_region, y_region)\n",
    "    \n",
    "\n",
    "    # Save the trained model\n",
    "    model_file = f'../model_deployment/model_pesticides_use/model_pesticides_use_{region}.joblib'\n",
    "    dump(model, model_file)\n",
    "    print(f\"Model for {region} saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f725d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to forecast the export value for a given region\n",
    "def forecast_export_value(region, year):\n",
    "    model = load(f'../model_deployment/model_pesticides_use/model_pesticides_use_{region}.joblib')\n",
    "    forecast_years = [year + i for i in range(1, 4)]\n",
    "    forecast_values = model.predict(pd.DataFrame({'Year': forecast_years}))\n",
    "    forecast_df = pd.DataFrame({'Year': forecast_years, 'Forecasted_Value': forecast_values})\n",
    "    return forecast_df\n",
    "\n",
    "# Perform forecasting for each geographical region\n",
    "regions = pesticides_use_area_concat['Area'].unique()\n",
    "forecast_results = {}   \n",
    "for region in regions:\n",
    "    forecast_results[region] = forecast_export_value(region, 2024)\n",
    "\n",
    "# Display the forecast results for each region\n",
    "for region, forecast_df in forecast_results.items():\n",
    "    print(f\"Forecast for {region}:\")\n",
    "    print(forecast_df)\n",
    "    print()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "countries_to_plot = ['Bahamas', 'Bangladesh', 'India']\n",
    "for country in countries_to_plot:\n",
    "    forecast_df = forecast_results[country]\n",
    "    sns.lineplot(data=forecast_df, x='Year', y='Forecasted_Value', label=country, linestyle='--')\n",
    "\n",
    "plt.title('Forecasted Export Value of Crop Products for Selected Countries')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Export Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f6427b",
   "metadata": {},
   "source": [
    "### All Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "def processDataset(dataset_path, model_name, model):\n",
    "    dataset = pd.read_csv(dataset_path)\n",
    "    \n",
    "    # Selected relevant features and handle missing values\n",
    "    selected_features = ['Area Code (M49)', 'Year Code', 'Value']\n",
    "    dataset_selected = dataset[selected_features].dropna()\n",
    "    \n",
    "    # Features (X) and target variable (y) define\n",
    "    X = dataset_selected[['Area Code (M49)', 'Year Code']]\n",
    "    y = dataset_selected['Value']\n",
    "    \n",
    "    # Datasets splited into training and testing sets (80%, 20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "   \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Store the prediction outputs into DataFrame\n",
    "    prediction_outputs = pd.DataFrame({\n",
    "        'Data Instance ID': X_test.index,\n",
    "        f'True Label ({model_name})': y_test,\n",
    "        f'Prediction ({model_name})': predictions\n",
    "    })\n",
    "    \n",
    "    return prediction_outputs\n",
    "\n",
    "\n",
    "\n",
    "# List of dataset paths\n",
    "dataset_paths = [\n",
    "    \"../Consumer prices indicators - FAOSTAT_data_en_2-22-2024.csv\",\n",
    "    \"../Crops production indicators - FAOSTAT_data_en_2-22-2024.csv\",\n",
    "    \"../Emissions - FAOSTAT_data_en_2-27-2024.csv\",\n",
    "    \"../Employment - FAOSTAT_data_en_2-27-2024.csv\",\n",
    "    \"../Exchange rate - FAOSTAT_data_en_2-22-2024.csv\",\n",
    "    \"../Fertilizers use - FAOSTAT_data_en_2-27-2024.csv\",\n",
    "    \"../Food balances indicators - FAOSTAT_data_en_2-22-2024.csv\",\n",
    "    \"../Food security indicators  - FAOSTAT_data_en_2-22-2024.csv\",\n",
    "    \"../Food trade indicators - FAOSTAT_data_en_2-22-2024.csv\",\n",
    "    \"../Foreign direct investment - FAOSTAT_data_en_2-27-2024.csv\",\n",
    "    # \"../Land temperature change - FAOSTAT_data_en_2-27-2024.csv\",\n",
    "    \"../Land use - FAOSTAT_data_en_2-22-2024.csv\",\n",
    "    \"../Pesticides use - FAOSTAT_data_en_2-27-2024.csv\",\n",
    "    ]\n",
    "\n",
    "# Initialize models\n",
    "linear_model = LinearRegression()\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "\n",
    "# List to store all prediction DataFrames\n",
    "all_predictions = []\n",
    "\n",
    "# This process each dataset and collect predictions\n",
    "for dataset_path in dataset_paths:\n",
    "    # This process dataset with linear regression\n",
    "    linear_predictions = processDataset(dataset_path, \"Linear Regression\", linear_model)\n",
    "    all_predictions.append(linear_predictions)\n",
    "    \n",
    "    # This process dataset with MLP regression\n",
    "    mlp_predictions = processDataset(dataset_path, \"MLP Regression\", mlp_model)\n",
    "    all_predictions.append(mlp_predictions)\n",
    "\n",
    "# Concatenates all prediction DataFrames\n",
    "all_predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
    "\n",
    "# And then save all concatenated DataFrame to a CSV file\n",
    "all_predictions_df.to_csv(\"../MLWorks/predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9493a91d",
   "metadata": {},
   "source": [
    "### Merging notbooks into one file and Convert the code file to PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af9ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "import nbformat\n",
    "# from nbconvert import PDFExporter\n",
    "\n",
    "notebooks = [\n",
    "    \"consumer_prices_indicators.ipynb\",\n",
    "    \"crops_production_indicators.ipynb\",\n",
    "    \"employment.ipynb\",\n",
    "    \"exchange_rate.ipynb\",\n",
    "    \"emissions.ipynb\",\n",
    "    \"fertilizers_use.ipynb\",\n",
    "    \"food_balances_indicators.ipynb\",\n",
    "    \"food_security_indicators.ipynb\",\n",
    "    \"food_trade_indicators.ipynb\",\n",
    "    \"foriegn_direct_investment.ipynb\",\n",
    "    \"land_temperature_change.ipynb\",\n",
    "    \"land_use.ipynb\",\n",
    "    \"pesticides_use.ipynb\",\n",
    "    \"predictions.ipynb\",\n",
    "    \n",
    "]\n",
    "\n",
    "merged_notebook = nbformat.v4.new_notebook()\n",
    "\n",
    "for notebook_file in notebooks:\n",
    "    with open(notebook_file, 'r', encoding='utf-8') as f:\n",
    "        notebook_content = nbformat.read(f, as_version=4)\n",
    "    merged_notebook.cells.extend(notebook_content.cells)\n",
    "output_file = 'all_notebook_code.ipynb'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    nbformat.write(merged_notebook, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1251f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
